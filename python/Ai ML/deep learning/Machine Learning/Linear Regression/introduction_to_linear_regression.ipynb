{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dphi-official/Data_Science_Bootcamp/blob/master/Week3/Linear_Regression/Introduction_to_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d1NlWnV4YE8"
   },
   "source": [
    "*Please go through the module on Linear Regression before starting with this notebook.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYxCBqraS5Yp"
   },
   "source": [
    "## Linear Regression Intuition\n",
    "Before we dive into the actual technique of Linear Regression, lets look at some intuition of it.\n",
    "\n",
    "Let’s say, I give you the following puzzle:\n",
    "\n",
    "Given the following values of X and Y, what is the value of Y when X = 5.\n",
    "\n",
    "(1,1), (2,2), (4,4), (100,100), (20, 20)\n",
    "\n",
    "The answer is : 5. Not very difficult, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xwew2jFKTEgv"
   },
   "source": [
    "Now, let’s take a look at different example. Say you have the following pairs of X and Y. Can you calculate the value of Y, when X = 5?\n",
    "\n",
    "(1,1), (2,4), (4,16), (100,10000), (20, 400)\n",
    "\n",
    "The answer is : 25. Was it difficult?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyEr2N6cTO1l"
   },
   "source": [
    "Let’s understand a bit as to what happened in the above examples. \n",
    "\n",
    "When we look at the first example, after looking at the given pairs, one can establish that the relationship between X and Y is Y = X. \n",
    "\n",
    "Similarly, in the second example, the relationship is Y = X*X.\n",
    "\n",
    "In these two examples, we can determine the relationship between two given variables (X and Y) because we could easily identify the relationship between them. Overall, machine learning works in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cx-ylUFzTcbu"
   },
   "source": [
    "Your computer looks at some examples and then tries to identify “the most suitable” relationship between the sets X and Y. Using this identified relationship, it will try to predict (or more) for new examples for which you don’t know Y.\n",
    "\n",
    "Keeping the above idea in mind, I will try to explain what is linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-zND2lHTlGT"
   },
   "source": [
    "## Regression\n",
    "Regression is usually termed as determining relationship(s) between two or more variables. \n",
    "\n",
    "For example, in the above two examples, X and Y are the variables. **X** is termed as the **independent variable** and **Y** is termed as the **dependent variable** (because its value is calculated using X).\n",
    "Also, Y has a continous range (unlike classification where Y is discrete).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWLyUvrmXZ6H"
   },
   "source": [
    "## Linear Regression/ Simple Linear Regression\n",
    "Simple Linear Regression (SLR) is termed as simple because there is only independent variable.\n",
    "\n",
    "Suppose we have a dataset which contains information about relationship between 'Years of experience' and 'Salary' in a particular work field.\n",
    "\n",
    "The **dependent variable could represent salary**. You could assume that level of experience will impact salary. So, you would label the **independent variable as experience**.\n",
    "\n",
    "Representing the experience with variable x and  salary with y, we can say that y ∝ x. ( y is proportional to x)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHz2ehdACJFN"
   },
   "source": [
    "However, a change in x does not usually mean an equal change in y.\n",
    "\n",
    "The **coefficient** can be thought of as a **multiplier that connects the independent and dependent variables.** It translates how much y will be affected by a unit change in x. \n",
    "\n",
    "Let's add a coefficient b1 to our example.\n",
    "\n",
    "We thus get y = b1*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKk2itK7Gw3i"
   },
   "source": [
    "Now the salaries in a particular job always start with the base amount or the lowest possible salary. We thus need to take that constant in consideration. \n",
    "\n",
    "The constant b0 would be the starting salary for someone with a zero level of experience. Assuming every fresher in the company gets 30K as starting salary we can set it as the base price.\n",
    "\n",
    "Finally, we have:\n",
    "\n",
    "Salary = b0 + b1* Experience\n",
    "\n",
    "or\n",
    "\n",
    "y = b0 + b1*x\n",
    "\n",
    "This is similar to the equation of a straight line y= m*x +c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3FeQSFaH3SB"
   },
   "source": [
    "![Equation](https://miro.medium.com/max/1400/1*MgZkzHNM6lNTtrfhV6SRcA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_nFb8ZRJTIX"
   },
   "source": [
    "Let's bring our theory into practice now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_c7y3fqWuDX"
   },
   "source": [
    "## Objective\n",
    "The objective is to use linear regression to understand how years of experience impact Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UEWLuXd7BMrU"
   },
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import numpy as np # to perform calculations \n",
    "import pandas as pd # to read data\n",
    "import matplotlib.pyplot as plt # to visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7zlSaTd2W9rt"
   },
   "outputs": [],
   "source": [
    "#Loading the salary dataset\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Linear_Regression_Introduction/master/Salary_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "k4C8FJ49BaPD",
    "outputId": "1bca6b85-6685-4c0a-d715-90d6d07f6199"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearsExperience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>39343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3</td>\n",
       "      <td>46205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>37731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>43525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2</td>\n",
       "      <td>39891.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YearsExperience   Salary\n",
       "0              1.1  39343.0\n",
       "1              1.3  46205.0\n",
       "2              1.5  37731.0\n",
       "3              2.0  43525.0\n",
       "4              2.2  39891.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's have a look at what our data is like\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOAV8pIdK96F"
   },
   "source": [
    "## Plotting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afk-xYG9TilK"
   },
   "source": [
    "Let’s plot our data points on a 2-D graph to eyeball our dataset(get a rough overview) and see if we can manually find any relationship between the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "jQCucd83K9DG",
    "outputId": "883a5f7f-8ce6-4bd0-a1f6-2b2e27c29c41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x209738558b0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatter plot helps in visualising the data distribution\n",
    "plt.plot(data.YearsExperience, data.Salary,'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7uUycDxW-Jw"
   },
   "source": [
    "As you can see, there is a clear relationship between the years of experience and salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhXicalATwLX"
   },
   "source": [
    "# Setting variables\n",
    "Our next step is to divide the data into “attributes” and “labels” or as you've already known as input and target variables.\n",
    "\n",
    "In our dataset, we only have two columns. We want to predict the Salary depending upon the Years of Experience recorded. Therefore our attribute set will consist of the “YearsExperience” column which is stored in the X variable, and the label will be the “Salary” column which is stored in y variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "699Bh6VPUFKb"
   },
   "outputs": [],
   "source": [
    "X = data[['YearsExperience']]\n",
    "y = data['Salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeJohYny3LNH"
   },
   "source": [
    "If you are wondering why a capital X is used for features, and lowercase y for labels, it is mainly due to convention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgXPagiS3YKz"
   },
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vOkLlB-Ukjn"
   },
   "source": [
    "Next, we split 80% of the data to the training set while 20% of the data to test set using below code.\n",
    "The test_size variable is where we actually specify the proportion of the test set.\n",
    "\n",
    "By passing our X and y variables into the train_test_split method, we are able to capture the splits in data by assigning 4 variables to the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1a1OFJmpUl2u"
   },
   "outputs": [],
   "source": [
    "# import SK Learn train test split\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Assign variables to capture train test split output\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvUH0MAtNI4d"
   },
   "source": [
    "# Understanding the working of Linear Regression\n",
    "\n",
    "The term “linearity” in algebra refers to a linear relationship between two or more variables. If we draw this relationship in a two-dimensional space (between two variables), we get a straight line.\n",
    "\n",
    "If we plot the independent variable (x) on the x-axis and dependent variable (y) on the y-axis, linear regression gives us a straight line that \"best fits\" the data points.It’s impossible to connect all the marks with a straight line, so you use a best fitting line. \n",
    "\n",
    "The equation for this line would be the result of your simple linear regression(Remember the equation y= b0 + b1*x that we just derived?). The regression finds the best fitting line.\n",
    "\n",
    "Now, how do you find the best fitting line? Since our data points(values of x and y) will remain constant for a particular dataset, we can only alter b0 and b1.\n",
    "\n",
    "**Our objective is to find the values of b0 and b1 that will best fit this data.**\n",
    "\n",
    "These 2 variables/coefficients are actually called **hyperparameters**. In machine learning, a hyperparameter is a parameter whose value is used to control the learning process. And we must always try to find some optimal parameters while building a machine learning model.\n",
    "\n",
    "This line is your **regression model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8Sh3OtwOdDw"
   },
   "source": [
    "To perform Linear Regression quickly, we will be using the library scikit-learn. If you don’t have it already you can install it using pip:\n",
    "\n",
    "\n",
    "```\n",
    "pip install scikit-learn \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwotIN0AU3Ci"
   },
   "source": [
    "# Training our model\n",
    "\n",
    "After splitting the data into training and testing sets, finally, the time is to train our algorithm. Firstly, importing of sklearn.linear_model is required for us to access LinearRegression. It then needs to be instantiated and model fit to our training data. This is seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0aBmpZc-OG46"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "GUoc8UA4PEnx",
    "outputId": "bb99f7ff-3aed-40d8-8c19-7568dd30f38f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regressor = LinearRegression()  # create object for the class\n",
    "\n",
    "#fit model to our training data i.e learn coefficients\n",
    "linear_regressor.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ac60llI46MYA"
   },
   "source": [
    "# Interpreting Coefficients\n",
    "The coefficients(b0 and b1) will allow us to model our equation with values and find the best fit line. The linear_regressor variable (assigned to a LinearRegression object), is able to have the intercept and coefficients extracted, using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "eMwzIRAd6h_c",
    "outputId": "5b4c0ac9-b5ab-4246-a46a-6b42dab28767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26634.24366972813\n",
      "[9374.26872553]\n"
     ]
    }
   ],
   "source": [
    "# prints y-intercept\n",
    "print(linear_regressor.intercept_)\n",
    "\n",
    "# prints the coefficient\n",
    "print(linear_regressor.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKv9fOH-7KwD"
   },
   "source": [
    "The intercept will be your b0 value; and coefficient will be b1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40gnRRSDVOH7"
   },
   "source": [
    "# Making predictions based on your model\n",
    "Now that we have trained our algorithm, it’s time to make some predictions. To do so, we will use our test data and see how accurately our algorithm predicts the salaries. \n",
    "\n",
    "Making predictions based on your model is as simple as using the code below: passing the predict method your test data. This will return predicted values of y given the new test X data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ognJglSBVO6v"
   },
   "outputs": [],
   "source": [
    "y_pred = linear_regressor.predict(X_test)  # make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGs81y8KQE24"
   },
   "source": [
    "We have our predictions in y_pred. Now lets visualize the data set and the regression line with the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "D5JfOaTBQGaJ",
    "outputId": "70edb51a-d777-4e2d-dc19-5389c6a9ab9c"
   },
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:142\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), None)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(X_test, y_pred, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:2757\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2755\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   2756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   2758\u001b[0m         \u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39mscalex, scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   2759\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:487\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    484\u001b[0m         kw[prop_name] \u001b[38;5;241m=\u001b[39m val\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xy) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 487\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m     y \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1327\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m w:\n\u001b[0;32m   1322\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1324\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mWarning\u001b[39;00m,\n\u001b[0;32m   1325\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSupport for multi-dimensional indexing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1327\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;66;03m# we have definitely hit a pandas index or series object\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;66;03m# cast to a numpy array.\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(w) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3628\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3623\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m         \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m         \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m         \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3628\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3629\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   3631\u001b[0m \u001b[38;5;66;03m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5637\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   5634\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5635\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5636\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5637\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), None)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_test, y_test,'rx')\n",
    "plt.plot(X_test, y_pred, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrGjcLi1YcsY"
   },
   "source": [
    "As you can see, the algorithm has drawn a line that passes through the maximum test data points and has the minimum distance from the others. This line is known as the \"best-fit\" or the regression line. \n",
    "\n",
    "Since this line has a positive slope, we can say that the salary increases as no. of years of experience increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9e3K6wjMISUP"
   },
   "source": [
    "![Simple Linear Regression](https://i0.wp.com/brokerstir.com/wp-content/uploads/2018/03/simple_linear_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkhXMY_9Zkvc"
   },
   "source": [
    "Using this line, you can even compute the salaries for the years of experience not present in the dataset by finding the corresponding value of y on the line.\n",
    "\n",
    "![Prediction](https://miro.medium.com/max/1400/1*ANtsE4kMZDAqueFPVk1jmg.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLvphULKwpUz"
   },
   "source": [
    "# Model Evaluation\n",
    "There are three primary metrics used to evaluate linear models. These are: Mean absolute error (MAE), Mean squared error (MSE), or Root mean squared error (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "QwhqScAXwpU1",
    "outputId": "aad63667-f24e-47cc-c6c7-9cd81fef16b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2620.866396501886\n",
      "13089573.359870747\n",
      "3617.951541946181\n"
     ]
    }
   ],
   "source": [
    "# import metrics library\n",
    "from sklearn import metrics\n",
    "\n",
    "# print result of MAE\n",
    "print(metrics.mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "#print result of MSE\n",
    "print(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "#print result of RMSE\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yo0aCl4wpU6"
   },
   "source": [
    "We'll be discussing about each of these metrics/performance parameters in detail soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJYO_QkuY7za"
   },
   "source": [
    "\n",
    "Congratulations! You've successfully completed your objective and created your own Linear Regression model."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "introduction_to_linear_regression-bef6c2d9690c497da79ed3d4279b5cc1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
